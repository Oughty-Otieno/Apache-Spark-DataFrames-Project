{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apache Spark DataFrames Project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN46KbvWKAuHKep3kQNiHa9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oughty-Otieno/Apache-Spark-DataFrames-Project/blob/main/Apache_Spark_DataFrames_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem statement\n",
        "\n",
        "As a Data professional, you need to perform an analysis by answering questions about\n",
        "some stock market data on Safaricom from the years 2012-2017.\n",
        "You will need to perform the following:\n",
        "\n",
        "Data Importation and Exploration\n",
        "\n",
        "● Start a spark session and load the stock file while inferring the data types.\n",
        "\n",
        "● Determine the column names\n",
        "\n",
        "● Make observations about the schema.\n",
        "\n",
        "● Show the first 5 rows\n",
        "\n",
        "● Use the describe method to learn about the data frame\n",
        "\n",
        "Data Preparation\n",
        "\n",
        "● Format all the data to 2 decimal places i.e. format_number()\n",
        "\n",
        "● Create a new data frame with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day\n",
        "\n",
        "Data Analysis\n",
        "\n",
        "● What day had the Peak High in Price?\n",
        "\n",
        "● What is the mean of the Close column?\n",
        "\n",
        "● What is the max and min of the Volume column?\n",
        "\n",
        "● How many days was the Close lower than 60 dollars?\n",
        "\n",
        "● What percentage of the time was the High greater than 80 dollars?\n",
        "\n",
        "● What is the Pearson correlation between High and Volume?\n",
        "\n",
        "● What is the max High per year?\n",
        "\n",
        "● What is the average Close for each Calendar Month?\n",
        "\n",
        "Data description\n",
        "\n",
        "Dataset URL (CSV File): https://bit.ly/3pmchk"
      ],
      "metadata": {
        "id": "-JFJRF2a11Wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Importation and Exploration"
      ],
      "metadata": {
        "id": "aRbiWZWl2Bt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start a spark session and load the stock file while inferring the data types."
      ],
      "metadata": {
        "id": "Q7vMWtND2JcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To use Pyspark in Colab, We'll first install it\n",
        "# ---\n",
        "#\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrYAkV742LK2",
        "outputId": "f5838307-74fb-4ec0-ee23-9dcf2f261cb1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 63.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=579ee53049cfcf2cf9221b948cc5809308b7e5696c83539e0404e62b93ccc6cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we'll run a local spark session\n",
        "# ---\n",
        "#\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "ewOYVTpP29MN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "y1oR5d6e8mxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SQLContext\n",
        "sqlCtx = SQLContext(sc)\n",
        "\n",
        "\n",
        "df = sqlCtx.read.csv(\"/content/saf_stock.csv\", header=True)\n",
        "\n",
        "# Print the type\n",
        "print(type(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1MlMB4j41dX",
        "outputId": "b717d473-24f4-4422-8929-6062bd50b4a3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the schema"
      ],
      "metadata": {
        "id": "W2IknOlV8rUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We can print the schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DshnQjzY6Xl0",
        "outputId": "7332d6b2-bb58-4eaf-d568-73484901140a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: string (nullable = true)\n",
            " |-- Volume: string (nullable = true)\n",
            " |-- Adj Close: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hz7typh8hU2",
        "outputId": "759c8cf7-3f4d-4f05-aaac-acc0f66bf0ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the columns\n"
      ],
      "metadata": {
        "id": "zk39wcVD88YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNuxeJWW8_GN",
        "outputId": "e60203c9-a21c-4f37-e81b-97bca1377e0f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the describe method to learn about the data frame"
      ],
      "metadata": {
        "id": "bw4hECMM9V63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the describe method to learn about the data frame Data Preparation\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD6SDBH-9Z22",
        "outputId": "a359aa96-22c7-45ec-f12a-5be535c506da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|      Date|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|      1258|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean|      null| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|      null|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|2012-01-03|56.389998999999996|        57.060001|        56.299999|        56.419998|         10010500|        50.363689|\n",
            "|    max|2016-12-30|         90.800003|        90.970001|            89.25|        90.470001|          9994400|84.91421600000001|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "pah0zKI39psn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format all the data to 2 decimal places i.e. format_number()"
      ],
      "metadata": {
        "id": "1N4Gscbo9u-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format all the data to 2 decimal places i.e. format_number()\n",
        "\n",
        "from pyspark.sql.functions import format_number\n",
        "\n",
        "df_2_decimal=df.select(df['Date'],format_number(df['Open'].cast('float'),2).alias('Open'),\n",
        "              format_number(df['High'].cast('float'), 2).alias('High'),\n",
        "              format_number(df['Low'].cast('float'), 2).alias('Low'),\n",
        "              format_number(df['Close'].cast('float'), 2).alias('Close'),\n",
        "              df['Volume'].cast('int').alias('Volume'),\n",
        "              format_number(df['Adj Close'].cast('float'), 2).alias('Adj Close')\n",
        "              )\n",
        "\n",
        "df_2_decimal.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_TyO2Om9yeN",
        "outputId": "0401d921-e4c1-47c0-811e-813511e0097e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|\n",
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|\n",
            "|2012-01-06|59.42|59.45|58.87|59.00| 8069400|    51.46|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|\n",
            "+----------+-----+-----+-----+-----+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "High Price versus volume of stock traded for a day\n"
      ],
      "metadata": {
        "id": "vGTq4Q6892AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new data frame with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day\n",
        "\n",
        "df_new = df_2_decimal.withColumn(\"HV Ratio\", format_number((df_2_decimal['High']/df_2_decimal['Volume']).cast('float'),8))\n",
        "print(df_new.show(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMnU2WMb93yF",
        "outputId": "90b03847-c47f-46a0-d4a1-e666d84cedbe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+--------+---------+----------+\n",
            "|      Date| Open| High|  Low|Close|  Volume|Adj Close|  HV Ratio|\n",
            "+----------+-----+-----+-----+-----+--------+---------+----------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|0.00000482|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|0.00000629|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|0.00000467|\n",
            "|2012-01-06|59.42|59.45|58.87|59.00| 8069400|    51.46|0.00000737|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|0.00000892|\n",
            "+----------+-----+-----+-----+-----+--------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis\n"
      ],
      "metadata": {
        "id": "IGa-llGN_ct4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What day had the Peak High in Price"
      ],
      "metadata": {
        "id": "dW8Nc_9X_jl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_new.orderBy(new_df['High'].desc()).head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVXffUYdAOPR",
        "outputId": "d6a7417a-4820-43aa-dd9a-0bbfd235b0c5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(Date='2015-01-13', Open='90.80', High='90.97', Low='88.93', Close='89.31', Volume=8215400, Adj Close='83.83', HV Ratio='0.00001107')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the mean of the Close column?"
      ],
      "metadata": {
        "id": "w7jfgMPoA1Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean, max, min\n",
        "\n",
        "print(df_new.select(mean('Close')).show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a5xNvJ2A1ru",
        "outputId": "f4bd2c82-aad2-40ed-f080-a4a743a6935a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       avg(Close)|\n",
            "+-----------------+\n",
            "|72.38844992050863|\n",
            "+-----------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the max and min of the Volume column?"
      ],
      "metadata": {
        "id": "kuyylAKyBBUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the max and min of the Volume column?\n",
        "print(df_new.select(min('Volume'),max('Volume')).show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TARDB6EZBB-P",
        "outputId": "10849fd4-5f8e-4b84-a174-654f6574a20d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|min(Volume)|max(Volume)|\n",
            "+-----------+-----------+\n",
            "|    2094900|   80898100|\n",
            "+-----------+-----------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " How many days was the Close lower than 60 dollars?"
      ],
      "metadata": {
        "id": "b3_VkEWTBInu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_new.filter(df_new['Close'] < 60).count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuSYsnz-BSaW",
        "outputId": "02760634-0d00-4a27-f268-7e23fdc523e0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " What percentage of the time was the High greater than 80 dollars?"
      ],
      "metadata": {
        "id": "-HzI8vKYBa5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print((df_new.filter(df_new['High']>80).count()/df_new.count()) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA8YIclmBbpi",
        "outputId": "7ef6e3cc-35cb-4183-cff0-7d95158a5c21"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.426073131955485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " What is the Pearson correlation between High and Volume?"
      ],
      "metadata": {
        "id": "nWviOpPABofo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import corr\n",
        "\n",
        "print(df_new.select(corr('High','Volume')).show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jUrpgF2Bpl_",
        "outputId": "c3e34924-861b-4d87-b101-9a50988f623b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|  corr(High, Volume)|\n",
            "+--------------------+\n",
            "|-0.33843260582148915|\n",
            "+--------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the max High per year?"
      ],
      "metadata": {
        "id": "kFoB696GCJpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "df_new.groupby(F.date_format('Date','yyyy').alias('Year')).agg({'High': 'max'}).sort('Year').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmxeXGAbCKVi",
        "outputId": "e6357248-ac74-45eb-976a-99266d3933bc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|Year|max(High)|\n",
            "+----+---------+\n",
            "|2012|    77.60|\n",
            "|2013|    81.37|\n",
            "|2014|    88.09|\n",
            "|2015|    90.97|\n",
            "|2016|    75.19|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the average Close for each Calendar Month?\n"
      ],
      "metadata": {
        "id": "yFUfKDk_CUaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.groupby(F.date_format('Date','MM').alias('Month')).agg({'Close': 'mean'}).sort('Month').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6YebAZ1CVC4",
        "outputId": "d5fcc381-e4e5-440e-d5f7-c667bb5b733d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|   01|71.44801980198022|\n",
            "|   02|71.30680412371134|\n",
            "|   03|71.77794392523363|\n",
            "|   04|72.97361904761907|\n",
            "|   05|72.30971698113206|\n",
            "|   06|72.49537735849057|\n",
            "|   07|74.43971962616824|\n",
            "|   08|73.02981818181819|\n",
            "|   09|72.18411764705883|\n",
            "|   10|71.57854545454546|\n",
            "|   11|72.11108910891085|\n",
            "|   12|72.84792452830189|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}